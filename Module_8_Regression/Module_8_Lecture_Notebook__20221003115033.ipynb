{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "006f5fcc",
   "metadata": {},
   "source": [
    "## POLSCI 3 Summer 2022\n",
    "\n",
    "## Week 8: Ordinary Least Squares (OLS) Regression\n",
    "\n",
    "In this notebook we will learn to code bivariate and multivariate regression and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f2067b",
   "metadata": {},
   "source": [
    "## OLS (bivariate) regression\n",
    "\n",
    "Ordinary Least Squares (OLS) regression is a method for assessing a linear relationship between an independent variable $X$ and a dependent (outcome) variable $Y$. Our equation for the regression model looks like this:\n",
    "$${Y_i = \\hat\\alpha + \\hat\\beta X_i + \\hat{u}_i}$$\n",
    "\n",
    "Here ($X_i$,$Y_i$) represent a sample data point. (There are n values of $i$, where n is the sample size.) $\\hat\\alpha$ and $\\hat\\beta$ represent the Y-intercept and the slope of the regression line, respectively. $\\hat{u}_i$ represents a sample residual (or error). We can see this visually by using a modified version of a function we used to understand correlations in model 7. The code below reproduces the figure we saw in the last module but also includes the regression line and a graphical representation of the residual for each point in the dataset. Note that the residual (error), the vertical distance between our data points and the regression line, is bigger for some data points that for others. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c57761a",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>\n",
    "        <a href=\"https://datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fds-modules%2Fpolisci-3&branch=main&urlpath=shiny%2Fpolisci-3%2FModule_8_Regression%2F\">\n",
    "        Link to interactive version of the cell below\n",
    "        </a>\n",
    "    </h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feff9ccf",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "x=runif(n=50, min=0, max=1)\n",
    "simcor = function (x, correlation) { \n",
    "    n = length(x)\n",
    "    ymean = 0\n",
    "    ysd = 1\n",
    "    y = rnorm(n) \n",
    "    z = correlation * scale(x)[,1] + sqrt(1 - correlation^2) * scale(resid(lm(y ~ x)))[,1] \n",
    "    yresult = ymean + ysd * z \n",
    "    yresult }\n",
    "y=simcor(x,.8)                                 # Try changing the 0.5 to something else between -1 and 1 \n",
    "                                               # and reexecuting cell\n",
    "plot(x,y)\n",
    "abline(lm(y~x))\n",
    "pre <- predict(lm(y~x))\n",
    "\n",
    "\n",
    "segments(x, y, x, pre, col=\"red\")               # plot distances between points and the regression line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d14735",
   "metadata": {},
   "source": [
    "Try editing the value of the correlation by replacing \".5\" in the code above with a higher correlation and reexecuting the cell. What happens to the residuals?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa52c40e",
   "metadata": {},
   "source": [
    "What values of $\\hat\\alpha$ and $\\hat\\beta$ represent the \"best fit\" line?  OLS regression defines it as that line\n",
    "that minimizes the sum of the squared residuals for each data point. Here are the corresponding values of $\\hat\\alpha$ (the Y-intercept) and $\\hat\\beta$ (the slope):\n",
    "\n",
    "$$\\hat\\beta  =  \\frac{\\sum_{i=1}^{n} (X_i - \\bar{X_i})(Y_i - \\bar{Y_i})}{\\sum_{i=1}^{n} (X_i - \\bar{X_i})^2}  $$\n",
    "\n",
    "$$\\hat\\alpha = \\bar{Y} - \\hat\\beta\\bar{X}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e116a501",
   "metadata": {},
   "source": [
    "With a large dataset it would be a huge hassle to compute these sums by hand. Fortunately R can easily do the calculations for us. We need to use the <code>lm(y~x)</code> function. (Note the tilde between $y$ and $x$.) The y represents an array of values for our dependent variable and x represents an array of values for the independent variable. Let's try running a bivariate (two-variable) regression for the simulated example above.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffcaac7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "lm(y~x)                      # This command computes the sample regression coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc36b65a",
   "metadata": {},
   "source": [
    "Now let's try running a bivariate regression on a real data set, using our happiness data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed358d68",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "happiness_data = read.csv('happiness_polity_2018.csv')\n",
    "head(happiness_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1ff179",
   "metadata": {},
   "source": [
    "Here is a refresher on the codebook for the happiness data:\n",
    "\n",
    "<code>polity2</code>: The \"Polity Score\" of the country, which measures its political system on a 21-pont scale \n",
    "ranging from -10 (hereditary monarchy) to +10 (consolidated democracy).\n",
    "\n",
    "<code>polity2_cat</code>: The political category the country is identified within. \"autocracies\" are on one end of \n",
    "the spectrum, \"anocracies\" are in the middle (semi-democracies), and \"democracies\" are at the top of the spectrum.\n",
    "\n",
    "<code>gdpcapita</code>: GDP per Capita (economic output per person)\n",
    "\n",
    "<code>gdpcapita_cat</code>: GDP/income category that the country falls into (based on GDP per capita)\n",
    "\n",
    "<code>happiness</code>: The country's happiness index, measured through surveys that require participants to rank \n",
    "their level of happiness based on an assortment of quality-of-life factors\n",
    "\n",
    "<code>happiness_cat</code>: Happiness category that the country falls into (based on happpiness indicator)\n",
    "\n",
    "<code>life_expectancy</code>: Average life expectancy in years\n",
    "\n",
    "<code>life_expectancy_cat</code>: Life Expectancy category that the country falls into"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8147e4e4",
   "metadata": {},
   "source": [
    "Suppose we hypothesize that happiness leads to a longer life. Happiness then becomes the independent variable\n",
    "and life expectancy becomes the dependent variable. Running the regression takes one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37a61ca7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = happiness_data$life_expectancy ~ happiness_data$happiness)\n",
       "\n",
       "Coefficients:\n",
       "             (Intercept)  happiness_data$happiness  \n",
       "                  38.198                     4.762  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm(happiness_data$life_expectancy ~ happiness_data$happiness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3472a91f",
   "metadata": {},
   "source": [
    "Recall from the lecture introducing regression that the formula for the regression line is given by: $$\\hat{Y} = \\hat\\alpha + \\hat\\beta X$$ or, in\n",
    "terms of our example: $$\\hat{Y} = 38.198 + 4.762X$$ \n",
    "\n",
    "Note that the equation for the *line* does not include the random error term $\\hat{u}$, and that we denote the predicted value of $Y$ as $\\hat{Y}$ to distinguish the data points $Y$ from their corresponding values on the regression line.\n",
    "\n",
    "Let's play with this equation a little. A country with a happiness value of zero ($X=0$) would have a predicted life expectancy of only 38.198 years!  For each unit increase in happiness the predicted life expectancy increases by 4.762 years. \n",
    "\n",
    "Note that this is all conditional on the veracity of the model we estimated. We could just as well have estimated the effect of increased life expectancy on overall happiness. Regression cannot tell us which is the \"right\" model to estimate!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0310bf76",
   "metadata": {},
   "source": [
    "Up to this point we have explored only the sample regression model. But recall that we are usually not interested\n",
    "in the sample estimates in and of themselves. Rather, we want to use the sample estimates $\\hat\\alpha$ and \n",
    "$\\hat\\beta$ to make inferences about the corresponding population parameters $\\alpha$ and $\\beta$. Suppose our happiness data from 2018 is actually a random sample of larger population of country-years. What can the sample \n",
    "values tell us about the unknown population parameters? For that we need to know the standard errors and t-values of $\\hat\\alpha$ and $\\hat\\beta$. To display those we embed our regression function in the `summary` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e969e553",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = happiness_data$life_expectancy ~ happiness_data$happiness)\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-13.7829  -2.0997   0.1834   3.0816   9.2125 \n",
       "\n",
       "Coefficients:\n",
       "                         Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)               38.1984     2.0503   18.63   <2e-16 ***\n",
       "happiness_data$happiness   4.7617     0.3649   13.05   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 4.512 on 129 degrees of freedom\n",
       "Multiple R-squared:  0.569,\tAdjusted R-squared:  0.5656 \n",
       "F-statistic: 170.3 on 1 and 129 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(lm(happiness_data$life_expectancy ~ happiness_data$happiness))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed12fcf",
   "metadata": {},
   "source": [
    "## Multiple Regression\n",
    "\n",
    "Our bivariate regression results are not the end of the story of the effect of happiness on life expectancy. The reason is the likelihood of omitted variable bias. Our sample estimated effect is an unbiased estimate of the population effect only in the unlikely scenario that we have included *all* explanatory variables that affect life expectancy and are corrrelated with happiness. But we know that life expectancy is probably more than just a function of happiness. Wealth probably matters too, and it is correlated with happiness. To generate less biased estimates of the effects of both wealth and happiness on life expectancy we need to include both wealth and happiness in a regression together. That is called multiple regression and the command to do it is a straightforward generalization of the command for bivariate regression. Note in the command below that the variable representing wealth is happiness$gdpcapita, and that it is added to the list of explanatory variables with a `+` sign. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb7f73ed",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = happiness_data$life_expectancy ~ happiness_data$happiness + \n",
       "    happiness_data$gdpcapita)\n",
       "\n",
       "Residuals:\n",
       "     Min       1Q   Median       3Q      Max \n",
       "-12.1814  -2.0457   0.6393   2.8786   7.1927 \n",
       "\n",
       "Coefficients:\n",
       "                          Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)              4.581e+01  2.435e+00  18.812  < 2e-16 ***\n",
       "happiness_data$happiness 2.891e+00  5.060e-01   5.713 7.39e-08 ***\n",
       "happiness_data$gdpcapita 1.278e-04  2.586e-05   4.942 2.37e-06 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 4.151 on 128 degrees of freedom\n",
       "Multiple R-squared:  0.638,\tAdjusted R-squared:  0.6324 \n",
       "F-statistic: 112.8 on 2 and 128 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(lm(happiness_data$life_expectancy ~ happiness_data$happiness + happiness_data$gdpcapita))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758df71e",
   "metadata": {},
   "source": [
    "#### Review\n",
    "\n",
    "In this module we learned three commands:\n",
    "\n",
    "`lm(y ~ x)` to estimate a linear model with one explanatory variable\n",
    "`summary(lm(y ~ x))` to display standard errors, t-values, and p-values for inference\n",
    "`summary(lm(y ~ x1 + x2))` to estimate a linear model with two explanatory variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81a5e64",
   "metadata": {},
   "source": [
    "#### Reminder about Peer Consulting Office Hours\n",
    "\n",
    "If you had trouble with any content in this notebook, Data Peer Consultants are here to help! You \n",
    "can view their locations and availabilites at this link: https://data.berkeley.edu/degrees/peer-advising.\n",
    "Peer Consultants are there to answer all data-related questions, whether it be about the content of this notebook,\n",
    "applications of data science in the world or other data science courses offered at Berkeley -- \n",
    "make sure to take advantage of this wonderful resource!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
